import os
import whisperx
import pandas as pd
import warnings
import torch
import traceback
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser

# Suppress warnings
#warnings.filterwarnings("ignore")

# Load environment variables
load_dotenv()

# Configuration
DEFAULT_AUDIO_PATH = "lecture.mp3"
DEFAULT_SYLLABUS_PATH = "syllabus.txt"
OUTPUT_TRANSCRIPTION = "lecture_transcription.csv"
OUTPUT_ANALYSIS = "lecture_analysis.txt"

# Try to get API tokens from environment variables first, then fallback to hardcoded values
HF_TOKEN = os.getenv("HF_TOKEN")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

print(f"–ü—Ä–æ–≤–µ—Ä—è—é –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –ª–µ–∫—Ü–∏–∏: {DEFAULT_AUDIO_PATH}")
print(f"–ü—Ä–æ–≤–µ—Ä—è—é –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å–∏–ª–ª–∞–±—É—Å–∞: {DEFAULT_SYLLABUS_PATH}")


if not os.path.exists(DEFAULT_AUDIO_PATH):
    raise FileNotFoundError(f"–û—à–∏–±–∫–∞: —Ñ–∞–π–ª {DEFAULT_AUDIO_PATH} –Ω–µ –Ω–∞–π–¥–µ–Ω.")
else:
    print(f"File exist path: {DEFAULT_AUDIO_PATH}")

if not os.path.exists(DEFAULT_SYLLABUS_PATH):
    raise FileNotFoundError(f"–û—à–∏–±–∫–∞: —Ñ–∞–π–ª {DEFAULT_SYLLABUS_PATH} –Ω–µ –Ω–∞–π–¥–µ–Ω.")
    print(f"File exist path: {DEFAULT_SYLLABUS_PATH}")


class DeviceManager:
    """Manages device selection and CUDA availability"""
    
    @staticmethod
    def get_optimal_device():
        """Determine the optimal device (CUDA or CPU) based on availability and functionality"""
        device = "cpu"
        if torch.cuda.is_available():
            try:
                # Test if CUDA actually works
                test_tensor = torch.zeros(1).cuda()
                del test_tensor
                device = "cuda"
                print(f"‚úÖ CUDA is working properly. Using device: {device}")
                print(f"   CUDA Device: {torch.cuda.get_device_name(0)}")
                print(f"   CUDA Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")
            except Exception as e:
                print(f"‚ö†Ô∏è CUDA is available but encountered an error: {e}")
                print("   Falling back to CPU")
        else:
            print("‚ÑπÔ∏è CUDA is not available. Using CPU instead.")
        
        return device
    
    @staticmethod
    def clear_cuda_cache():
        """Clear CUDA cache if available"""
        if torch.cuda.is_available():
            try:
                torch.cuda.empty_cache()
                print("üßπ CUDA memory cleared")
                return True
            except Exception as e:
                print(f"‚ö†Ô∏è Failed to clear CUDA cache: {e}")
        return False


class AudioProcessor:
    """Processes audio files for transcription and speaker diarization"""
    
    def __init__(self, device="cpu"):
        self.device = device
        
        # Set parameters based on available device
        self.batch_size = 16 if device == "cuda" else 8
        self.compute_type = "float16" if device == "cuda" else "int8"
        
        print(f"üîß Initializing with: device={device}, batch_size={self.batch_size}, compute_type={self.compute_type}")
        
        try:
            print("üìù Loading WhisperX model...")
            # Handle potential CUDA errors gracefully
            try:
                self.model = whisperx.load_model("large-v3", self.device, compute_type=self.compute_type)
            except Exception as e:
                print(f"‚ö†Ô∏è Failed to load model on {self.device}: {e}")
                print("   Falling back to CPU")
                self.device = "cpu"
                self.compute_type = "int8"
                self.batch_size = 8
                self.model = whisperx.load_model("large-v3", self.device, compute_type=self.compute_type)
            
            print("üéôÔ∏è Loading diarization pipeline...")
            try:
                self.diarize_model = whisperx.DiarizationPipeline(use_auth_token=HF_TOKEN, device=self.device)
            except Exception as e:
                print(f"‚ö†Ô∏è Failed to load diarization model on {self.device}: {e}")
                print("   Falling back to CPU for diarization")
                self.diarize_model = whisperx.DiarizationPipeline(use_auth_token=HF_TOKEN, device="cpu")
                
            print("‚úÖ Models loaded successfully")
        except Exception as e:
            print(f"‚ùå Error loading models: {e}")
            print(f"   Details: {traceback.format_exc()}")
            raise

    def transcribe_audio(self, audio_file):
        """Transcribe audio file with speaker diarization"""
        try:
            print("üîä Loading audio...")
            audio = whisperx.load_audio(audio_file)
            
            print("üéØ Transcribing with WhisperX...")
            result = self.model.transcribe(audio, batch_size=self.batch_size)
            print(f"üåê Detected language: {result['language']}")
            
            print("‚öôÔ∏è Loading alignment model...")
            # Use CPU for alignment if CUDA has issues
            align_device = self.device
            try:
                model_a, metadata = whisperx.load_align_model(language_code=result["language"], device=align_device)
            except Exception as e:
                print(f"‚ö†Ô∏è Falling back to CPU for alignment due to error: {e}")
                align_device = "cpu"
                model_a, metadata = whisperx.load_align_model(language_code=result["language"], device=align_device)
            
            print("üìä Aligning segments...")
            result = whisperx.align(result["segments"], model_a, metadata, audio, align_device, return_char_alignments=False)
            
            print("üë• Running speaker diarization...")
            diarize_segments = self.diarize_model(audio)
            
            print("üîÑ Assigning speakers to words...")
            result = whisperx.assign_word_speakers(diarize_segments, result)
            
            print("‚úÖ Transcription complete")
            return result
        except Exception as e:
            print(f"‚ùå Error processing audio: {e}")
            print(f"   Details: {traceback.format_exc()}")
            return None

    def convert_to_df(self, result): 
        """Convert transcription result to DataFrame"""
        if result is None:
            print("‚ùå Error: transcription result is missing.")
            return None
        try:
            df = pd.DataFrame(result["segments"])
            # Ensure all necessary columns exist
            required_columns = ["start", "end", "text", "speaker"]
            for col in required_columns:
                if col not in df.columns:
                    print(f"‚ö†Ô∏è Warning: '{col}' column missing from transcription result")
                    if col == "speaker":
                        df["speaker"] = "UNKNOWN"
            
            # Select only the required columns
            df = df[required_columns]
            return df
        except Exception as e:
            print(f"‚ùå Error converting to DataFrame: {e}")
            print(f"   Details: {traceback.format_exc()}")
            return None


class LectureAnalyzer:
    """Analyzes lecture content using AI"""

    def __init__(self, api_key=None):
        self.api_key = api_key or GEMINI_API_KEY
        try:
            self.llm = ChatGoogleGenerativeAI(model="gemini-1.5-flash", google_api_key=self.api_key)
            print("‚úÖ Initialized Gemini model successfully")
        except Exception as e:
            print(f"‚ùå Error initializing Gemini model: {e}")
            raise
            
        self.prompt_template = """
        –¢—ã –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—à—å –ª–µ–∫—Ü–∏—é. –¢–≤–æ–∏ –∑–∞–¥–∞—á–∏:
        1. –û–ø—Ä–µ–¥–µ–ª–∏, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –ª–∏ –ª–µ–∫—Ü–∏—è —Ç–µ–º–µ, –∑–∞–¥–∞–Ω–Ω–æ–π –≤ —Å–∏–ª–ª–∞–±—É—Å–µ.
        2. –ù–∞–π–¥–∏ –ª—é–±—ã–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –æ—Ç —Ç–µ–º—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ª–∏—á–Ω—ã–µ —Ä–∞—Å—Å–∫–∞–∑—ã –ª–µ–∫—Ç–æ—Ä–∞).
        3. –û—Ü–µ–Ω–∏ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –ø–æ —á–∏—Å–ª—É –∏—Ö —Ä–µ–ø–ª–∏–∫.
        4. –í—ã–¥–µ–ª–∏ –∫–ª—é—á–µ–≤—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ –∏ —Ç–µ—Ä–º–∏–Ω—ã, —É–ø–æ–º—è–Ω—É—Ç—ã–µ –≤ –ª–µ–∫—Ü–∏–∏.
        5. –û—Ü–µ–Ω–∏ —è—Å–Ω–æ—Å—Ç—å –∏–∑–ª–æ–∂–µ–Ω–∏—è –º–∞—Ç–µ—Ä–∏–∞–ª–∞.

        **–°–∏–ª–ª–∞–±—É—Å:**  
        {syllabus}

        **–õ–µ–∫—Ü–∏—è:**  
        {lecture_text}

        **–û—Ç–≤–µ—Ç:**  
        - –õ–µ–∫—Ü–∏—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ç–µ–º–µ? (–î–∞/–ù–µ—Ç)  
        - –ö–∞–∫–∏–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –æ—Ç —Ç–µ–º—ã –±—ã–ª–∏ –∑–∞–º–µ—á–µ–Ω—ã?  
        - –ù–∞—Å–∫–æ–ª—å–∫–æ –∞–∫—Ç–∏–≤–Ω—ã —Å—Ç—É–¥–µ–Ω—Ç—ã (1-10)?
        - –ö–ª—é—á–µ–≤—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ –∏ —Ç–µ—Ä–º–∏–Ω—ã:
        - –Ø—Å–Ω–æ—Å—Ç—å –∏–∑–ª–æ–∂–µ–Ω–∏—è (1-10):
        - –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é:
        """

        self.prompt = PromptTemplate(template=self.prompt_template, input_variables=["syllabus", "lecture_text"])
        self.output_chain = self.prompt | self.llm | StrOutputParser()

    def analyze_lecture(self, syllabus, lecture_text):
        """Evaluate lecture against syllabus and criteria"""
        try:
            return self.output_chain.invoke({"syllabus": syllabus, "lecture_text": lecture_text})
        except Exception as e:
            print(f"‚ùå Error analyzing lecture: {e}")
            print(f"   Details: {traceback.format_exc()}")
            return f"Error analyzing lecture: {e}"


class LectureProcessingPipeline:
    """End-to-end pipeline for lecture processing"""
    
    def __init__(self, audio_path=DEFAULT_AUDIO_PATH, syllabus_path=DEFAULT_SYLLABUS_PATH):
        self.audio_path = audio_path
        self.syllabus_path = syllabus_path
        self.device = DeviceManager.get_optimal_device()
        self.processor = None
        self.analyzer = None
        self.syllabus_text = None
        self.df = None

    def validate_files(self):
        """Validate that required files exist"""
        if not os.path.exists(self.audio_path):
            print(f"‚ùå Error: Audio file not found: {self.audio_path}")
            return False
        
        if not os.path.exists(self.syllabus_path):
            print(f"‚ùå Error: Syllabus file not found: {self.syllabus_path}")
            return False
            
        return True
        
    def load_syllabus(self):
        """Load syllabus from file"""
        try:
            with open(self.syllabus_path, "r", encoding="utf-8") as f:
                self.syllabus_text = f.read()
            print(f"‚úÖ Syllabus loaded from {self.syllabus_path}")
            return True
        except Exception as e:
            print(f"‚ùå Error loading syllabus: {e}")
            return False
            
    def initialize_components(self):
        """Initialize processor and analyzer"""
        try:
            # Clear CUDA cache before initializing
            DeviceManager.clear_cuda_cache()
            
            self.processor = AudioProcessor(device=self.device)
            self.analyzer = LectureAnalyzer()
            return True
        except Exception as e:
            print(f"‚ùå Error initializing components: {e}")
            print(f"   Details: {traceback.format_exc()}")
            return False
            
    def process_audio(self):
        """Process audio file and convert to DataFrame"""
        try:
            result = self.processor.transcribe_audio(self.audio_path)
            self.df = self.processor.convert_to_df(result)
            
            if self.df is None or self.df.empty:
                print("‚ùå Error: Empty transcription result")
                return False
                
            return True
        except Exception as e:
            print(f"‚ùå Error processing audio: {e}")
            print(f"   Details: {traceback.format_exc()}")
            return False
            
    def save_transcription(self, output_path=OUTPUT_TRANSCRIPTION):
        """Save transcription to CSV file"""
        try:
            self.df.to_csv(output_path, index=False, encoding="utf-8")
            print(f"‚úÖ Transcription saved to {output_path}")
            return True
        except Exception as e:
            print(f"‚ùå Error saving transcription: {e}")
            return False
            
    def analyze_content(self):
        """Analyze lecture content"""
        try:
            lecture_text = " ".join(self.df["text"].tolist())
            analysis = self.analyzer.analyze_lecture(self.syllabus_text, lecture_text)
            return analysis
        except Exception as e:
            print(f"‚ùå Error analyzing content: {e}")
            print(f"   Details: {traceback.format_exc()}")
            return None
            
    def save_analysis(self, analysis, output_path=OUTPUT_ANALYSIS):
        """Save analysis to text file"""
        try:
            with open(output_path, "w", encoding="utf-8") as f:
                f.write(analysis)
            print(f"‚úÖ Analysis saved to {output_path}")
            return True
        except Exception as e:
            print(f"‚ùå Error saving analysis: {e}")
            return False
            
    def run(self):
        """Run the complete pipeline"""
        print("üöÄ Starting lecture processing pipeline...")
        
        if not self.validate_files():
            return False
            
        if not self.load_syllabus():
            return False
            
        if not self.initialize_components():
            return False
            
        if not self.process_audio():
            return False
            
        if not self.save_transcription():
            return False
            
        analysis = self.analyze_content()
        if analysis is None:
            return False
            
        if not self.save_analysis(analysis):
            return False
            
        print("‚úÖ Pipeline completed successfully")
        return True
        
    def cleanup(self):
        """Clean up resources"""
        try:
            # Delete model references
            if self.processor:
                if hasattr(self.processor, 'model'):
                    del self.processor.model
                if hasattr(self.processor, 'diarize_model'):
                    del self.processor.diarize_model
            
            # Clear CUDA memory
            DeviceManager.clear_cuda_cache()
            
            print("üßπ Cleanup completed")
        except Exception as e:
            print(f"‚ö†Ô∏è Error during cleanup: {e}")


def main():
    """Main function to run the pipeline"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Process lecture audio and analyze content")
    parser.add_argument("--audio", default=DEFAULT_AUDIO_PATH, help="Path to audio file")
    parser.add_argument("--syllabus", default=DEFAULT_SYLLABUS_PATH, help="Path to syllabus file")
    parser.add_argument("--output-transcription", default=OUTPUT_TRANSCRIPTION, help="Path to save transcription")
    parser.add_argument("--output-analysis", default=OUTPUT_ANALYSIS, help="Path to save analysis")
    
    args = parser.parse_args()
    
    pipeline = LectureProcessingPipeline(args.audio, args.syllabus)
    
    try:
        success = pipeline.run()
        if success:
            print("üéâ Processing completed successfully")
        else:
            print("‚ö†Ô∏è Processing completed with errors")
    except Exception as e:
        print(f"‚ùå Unhandled error: {e}")
        print(f"   Details: {traceback.format_exc()}")
    finally:
        pipeline.cleanup()


if __name__ == "__main__":
    main()



# –ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —É–ª—É—á—à–µ–Ω–Ω—É—é –ø—Ä–æ–≥—Ä–∞–º–º—É –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ª–µ–∫—Ü–∏–π
# –í–æ—Ç –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –ø—Ä–æ–≥—Ä–∞–º–º—ã:
# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ñ–∞–π–ª–æ–≤

# –ü–æ–¥–≥–æ—Ç–æ–≤—å—Ç–µ –∞—É–¥–∏–æ—Ñ–∞–π–ª –ª–µ–∫—Ü–∏–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –≤ —Ñ–æ—Ä–º–∞—Ç–µ MP3)
# –°–æ–∑–¥–∞–π—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª —Å —Å–∏–ª–ª–∞–±—É—Å–æ–º (—É—á–µ–±–Ω—ã–º –ø–ª–∞–Ω–æ–º)

# –ó–∞–ø—É—Å–∫ –ø—Ä–æ–≥—Ä–∞–º–º—ã
# –ë–∞–∑–æ–≤—ã–π –∑–∞–ø—É—Å–∫ (—Å –ø—É—Ç—è–º–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
# bashCopypython lecture_analyzer.py
# –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø—Ä–æ–≥—Ä–∞–º–º–∞ –±—É–¥–µ—Ç –∏—Å–∫–∞—Ç—å —Ñ–∞–π–ª—ã:

# lecture.mp3 - –∞—É–¥–∏–æ—Ñ–∞–π–ª –ª–µ–∫—Ü–∏–∏
# syllabus.txt - —Ñ–∞–π–ª —Å–∏–ª–ª–∞–±—É—Å–∞

# –ó–∞–ø—É—Å–∫ —Å —É–∫–∞–∑–∞–Ω–∏–µ–º –ø—É—Ç–µ–π –∫ —Ñ–∞–π–ª–∞–º
# bashCopypython lecture_analyzer.py --audio "–ø—É—Ç—å/–∫/–ª–µ–∫—Ü–∏–∏.mp3" --syllabus "–ø—É—Ç—å/–∫/—Å–∏–ª–ª–∞–±—É—Å—É.txt"
# –ü–æ–ª–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—É—Å–∫–∞
# bashCopypython lecture_analyzer.py --audio "–ø—É—Ç—å/–∫/–ª–µ–∫—Ü–∏–∏.mp3" --syllabus "–ø—É—Ç—å/–∫/—Å–∏–ª–ª–∞–±—É—Å—É.txt" --output-transcription "—Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è.csv" --output-analysis "–∞–Ω–∞–ª–∏–∑.txt"
# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏

# --audio: –ø—É—Ç—å –∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª—É –ª–µ–∫—Ü–∏–∏
# --syllabus: –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å–∏–ª–ª–∞–±—É—Å–∞
# --output-transcription: –∏–º—è —Ñ–∞–π–ª–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ (CSV-—Ñ–æ—Ä–º–∞—Ç)
# --output-analysis: –∏–º—è —Ñ–∞–π–ª–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∞–Ω–∞–ª–∏–∑–∞ –ª–µ–∫—Ü–∏–∏ (—Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç)

# –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ä–∞–±–æ—Ç—ã
# –ü–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–∞–º–º–∞ —Å–æ–∑–¥–∞—Å—Ç –¥–≤–∞ —Ñ–∞–π–ª–∞:

# lecture_transcription.csv - —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –ª–µ–∫—Ü–∏–∏ —Å —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º –ø–æ —Å–ø–∏–∫–µ—Ä–∞–º
# lecture_analysis.txt - –∞–Ω–∞–ª–∏–∑ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è –ª–µ–∫—Ü–∏–∏

# –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è
# –î–ª—è —Ä–∞–±–æ—Ç—ã –ø—Ä–æ–≥—Ä–∞–º–º—ã –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã:

# Python 3.8 –∏–ª–∏ –≤—ã—à–µ
# –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏: whisperx, pandas, torch, langchain_google_genai, dotenv
# API-–∫–ª—é—á–∏ –¥–ª—è Hugging Face –∏ Gemini API

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è
# –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —Å–æ–∑–¥–∞—Ç—å —Ñ–∞–π–ª .env –≤ —Ç–æ–π –∂–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –ø—Ä–æ–≥—Ä–∞–º–º–æ–π –∏ –¥–æ–±–∞–≤–∏—Ç—å –≤ –Ω–µ–≥–æ API-–∫–ª—é—á–∏:
# CopyHF_TOKEN=–≤–∞—à_–∫–ª—é—á_huggingface
# GEMINI_API_KEY=–≤–∞—à_–∫–ª—é—á_gemini
# –ï—Å–ª–∏ —Ñ–∞–π–ª .env –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç, –ø—Ä–æ–≥—Ä–∞–º–º–∞ –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑ –∫–æ–¥–∞.
# –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

# –ï—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å GPU —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π CUDA, –ø—Ä–æ–≥—Ä–∞–º–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –µ–≥–æ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
# –ü—Ä–∏ –≤–æ–∑–Ω–∏–∫–Ω–æ–≤–µ–Ω–∏–∏ –ø—Ä–æ–±–ª–µ–º —Å CUDA, –ø—Ä–æ–≥—Ä–∞–º–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—Å—è –Ω–∞ CPU
# –î–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –∞—É–¥–∏–æ–∑–∞–ø–∏—Å–µ–π –ø—Ä–æ—Ü–µ—Å—Å –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ –≤—Ä–µ–º—è, –æ—Å–æ–±–µ–Ω–Ω–æ –Ω–∞ CPU

# –ü—Ä–æ–≥—Ä–∞–º–º–∞ –≤—ã–≤–æ–¥–∏—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –æ —Ö–æ–¥–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è, —á—Ç–æ –ø–æ–º–æ–∂–µ—Ç –æ—Ç—Å–ª–µ–¥–∏—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å –∏ –æ–±–Ω–∞—Ä—É–∂–∏—Ç—å –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã.